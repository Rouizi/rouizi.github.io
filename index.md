---
layout: single
title: "My Projects"
permalink: /
author_profile: true
---

Explore some of the projects I’ve worked on. Click any project for more details.

## [4D Perception](https://github.com/Rouizi/4d-perception)

![](assets/images/merged_mot_to_view.gif)

In this project, I learned how to do 3D object detection, tracking, and visualization using LiDAR and camera data.

## [Visual Fusion](https://github.com/Rouizi/visual-fusion)

![](assets/images/early_fusion.gif)

Early and late fusion techniques to combine LiDAR point clouds and camera images for obstacle detection.

## [Bird’s Eye View Perception](https://github.com/Rouizi/bird-eye-view)

![](assets/images/bird_eye_view.gif)

This repository contains my work on **Bird’s Eye View (BEV) transformation** using both classical and deep learning methods.

## [Deep Learning on Point Clouds]([https://github.com/Rouizi/stereo-depth-estimation](https://github.com/Rouizi/deep-point-cloud))

![](assets/images/classification.png)

End-to-End implementation of deep learning architectures for 3D point cloud understanding.

Built and trained **PointNet** and a **Voxel-Based 3D CNN** from scratch using the ShapeNet Core dataset — covering everything from data preprocessing to model visualization.

## [Point Cloud Perception]([https://github.com/Rouizi/stereo-depth-estimation](https://github.com/Rouizi/point-cloud))

![](assets/images/reflectance_output.gif)

This project demonstrates how to process, segment, and transform raw LiDAR data into meaningful 3D scene understanding for autonomous driving tasks.

## [Stereo Depth Estimation](https://github.com/Rouizi/stereo-depth-estimation)

![](assets/images/streo-depth-estimation.gif)

This project explores **stereo vision** techniques for depth estimation.
It covers camera calibration, disparity map generation, depth map computation, and obstacle detection in 3D from stereo images.
